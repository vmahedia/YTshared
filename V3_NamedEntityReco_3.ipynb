{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on identifying named entities in text data (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science With Raghav\n",
    "**Youtube channel - https://www.youtube.com/channel/UC86OgfmVfguW69_0uIEffVQ/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Named Entity?\n",
    "\n",
    "**Any word which reprsents a person, organization, location etc. is a Named Entity.**\n",
    "**Named entity recognition is a subtask of Information Extraction and is the process of identifying words which are named entities in a given text.**\n",
    "**It is also called entity identification or entity chunking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "**\"Apple acquired Zoom in China on Wednesday 6th May 2020\"**\n",
    "\n",
    "- Here named entities are Apple, Zoom, China and Wednesday 6th May 2020\"\n",
    "- Named entity recognition is the task of identifying these words from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why it is important?\n",
    "\n",
    "**In order to understand the meaning from a given text (for ex a tweet or document), it is important to identify who did what to whom. Named entity recognition is the first task of identifying the words which may represnt the who, what and whom in the text. It helps in identifying the major entities the text is talking about**\n",
    "\n",
    "**Any NLP task which involves automatically understanding text and acts based on it, needs Named Entity Recognition in its pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat\n",
    "\n",
    "**No algorithm can 100% identify all the named entities correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three approaches\n",
    "\n",
    "- **Basic NLTK algorithm**\n",
    "    - with word segmentation\n",
    "    - with sentence segmentation\n",
    "- **Stanford NLP NER**\n",
    "- **Using Spacy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple acquired Zoom in China on Wednesday 6th May 2020.\\\n",
    "This news has made Apple and Google stock jump by 5% on Dow Jones Index in the \\\n",
    "United States of America\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Named Entity (NE) tagging using NLTK - Word based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'acquired',\n",
       " 'Zoom',\n",
       " 'in',\n",
       " 'China',\n",
       " 'on',\n",
       " 'Wednesday',\n",
       " '6th',\n",
       " 'May',\n",
       " '2020.This',\n",
       " 'news',\n",
       " 'has',\n",
       " 'made',\n",
       " 'Apple',\n",
       " 'and',\n",
       " 'Google',\n",
       " 'stock',\n",
       " 'jump',\n",
       " 'by',\n",
       " '5',\n",
       " '%',\n",
       " 'on',\n",
       " 'Dow',\n",
       " 'Jones',\n",
       " 'Index',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'of',\n",
       " 'America']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize to words\n",
    "words = nltk.word_tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apple', 'NNP'),\n",
       " ('acquired', 'VBD'),\n",
       " ('Zoom', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('China', 'NNP'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('6th', 'CD'),\n",
       " ('May', 'NNP'),\n",
       " ('2020.This', 'CD'),\n",
       " ('news', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('made', 'VBN'),\n",
       " ('Apple', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Google', 'NNP'),\n",
       " ('stock', 'NN'),\n",
       " ('jump', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('5', 'CD'),\n",
       " ('%', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Dow', 'NNP'),\n",
       " ('Jones', 'NNP'),\n",
       " ('Index', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('of', 'IN'),\n",
       " ('America', 'NNP')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part of speech tagging\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "#check nltk help for description of the tag\n",
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ne_chunk**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary=True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NE Apple/NNP)\n",
      "('acquired', 'VBD')\n",
      "('Zoom', 'NNP')\n",
      "('in', 'IN')\n",
      "(NE China/NNP)\n",
      "('on', 'IN')\n",
      "('Wednesday', 'NNP')\n",
      "('6th', 'CD')\n",
      "('May', 'NNP')\n",
      "('2020.This', 'CD')\n",
      "('news', 'NN')\n",
      "('has', 'VBZ')\n",
      "('made', 'VBN')\n",
      "(NE Apple/NNP)\n",
      "('and', 'CC')\n",
      "(NE Google/NNP)\n",
      "('stock', 'NN')\n",
      "('jump', 'NN')\n",
      "('by', 'IN')\n",
      "('5', 'CD')\n",
      "('%', 'NN')\n",
      "('on', 'IN')\n",
      "('Dow', 'NNP')\n",
      "('Jones', 'NNP')\n",
      "('Index', 'NNP')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "(NE United/NNP States/NNPS)\n",
      "('of', 'IN')\n",
      "(NE America/NNP)\n"
     ]
    }
   ],
   "source": [
    "chunks = nltk.ne_chunk(pos_tags, binary=True) #either NE or not NE\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>America</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entities Labels\n",
       "0          Apple     NE\n",
       "1        America     NE\n",
       "2  United States     NE\n",
       "3          China     NE\n",
       "4         Google     NE"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities =[]\n",
    "labels =[]\n",
    "for chunk in chunks:\n",
    "    if hasattr(chunk,'label'):\n",
    "        #print(chunk)\n",
    "        entities.append(' '.join(c[0] for c in chunk))\n",
    "        labels.append(chunk.label())\n",
    "        \n",
    "entities_labels = list(set(zip(entities, labels)))\n",
    "entities_df = pd.DataFrame(entities_labels)\n",
    "entities_df.columns = [\"Entities\",\"Labels\"]\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why did it miss Zoom?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary = False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON Apple/NNP)\n",
      "('acquired', 'VBD')\n",
      "(PERSON Zoom/NNP)\n",
      "('in', 'IN')\n",
      "(GPE China/NNP)\n",
      "('on', 'IN')\n",
      "('Wednesday', 'NNP')\n",
      "('6th', 'CD')\n",
      "('May', 'NNP')\n",
      "('2020.This', 'CD')\n",
      "('news', 'NN')\n",
      "('has', 'VBZ')\n",
      "('made', 'VBN')\n",
      "(PERSON Apple/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Google/NNP)\n",
      "('stock', 'NN')\n",
      "('jump', 'NN')\n",
      "('by', 'IN')\n",
      "('5', 'CD')\n",
      "('%', 'NN')\n",
      "('on', 'IN')\n",
      "(PERSON Dow/NNP Jones/NNP Index/NNP)\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "(GPE United/NNP States/NNPS)\n",
      "('of', 'IN')\n",
      "(GPE America/NNP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zoom</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dow Jones Index</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United States</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>America</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Entities        Labels\n",
       "0            Apple        PERSON\n",
       "1           Google  ORGANIZATION\n",
       "2             Zoom        PERSON\n",
       "3            China           GPE\n",
       "4  Dow Jones Index        PERSON\n",
       "5    United States           GPE\n",
       "6          America           GPE"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = nltk.ne_chunk(pos_tags, binary=False) #either NE or not NE\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "    \n",
    "entities =[]\n",
    "labels =[]\n",
    "for chunk in chunks:\n",
    "    if hasattr(chunk,'label'):\n",
    "        #print(chunk)\n",
    "        entities.append(' '.join(c[0] for c in chunk))\n",
    "        labels.append(chunk.label())\n",
    "        \n",
    "entities_labels = list(set(zip(entities, labels)))\n",
    "entities_df = pd.DataFrame(entities_labels)\n",
    "entities_df.columns = [\"Entities\",\"Labels\"]\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Named Entity (NE) tagging using NLTK - Sentence based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zoom</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dow Jones Index</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United States</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>America</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Entities        Labels\n",
       "0            Apple        PERSON\n",
       "1           Google  ORGANIZATION\n",
       "2             Zoom        PERSON\n",
       "3            China           GPE\n",
       "4  Dow Jones Index        PERSON\n",
       "5    United States           GPE\n",
       "6          America           GPE"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = []\n",
    "labels = []\n",
    "\n",
    "sentence = nltk.sent_tokenize(text)\n",
    "for sent in sentence:\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)),binary=False):\n",
    "        if hasattr(chunk,'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))\n",
    "            labels.append(chunk.label())\n",
    "            \n",
    "entities_labels = list(set(zip(entities,labels)))\n",
    "\n",
    "entities_df = pd.DataFrame(entities_labels)\n",
    "entities_df.columns = [\"Entities\",\"Labels\"]\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford NLP NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installation and Configuration:**\n",
    "https://medium.com/manash-en-blog/configuring-stanford-parser-and-stanford-ner-tagger-with-nltk-in-python-on-windows-f685483c374a\n",
    "\n",
    "**Stanford link:** https://nlp.stanford.edu/software/CRF-NER.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More powerful package than NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'C:/StanfordNER_Tagger/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "jar = 'C:/StanfordNER_Tagger/stanford-ner-2018-10-16/stanford-ner.jar'\n",
    "\n",
    "\n",
    "\n",
    "st = StanfordNERTagger(model, jar,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acquired</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zoom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6th</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>May</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020.This</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>has</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stock</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jump</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>%</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dow</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jones</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Index</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>United</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>States</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>of</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>America</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entities        Labels\n",
       "0       Apple  ORGANIZATION\n",
       "1    acquired             O\n",
       "2        Zoom             O\n",
       "3          in             O\n",
       "4       China      LOCATION\n",
       "5          on             O\n",
       "6   Wednesday             O\n",
       "7         6th             O\n",
       "8         May             O\n",
       "9   2020.This             O\n",
       "10       news             O\n",
       "11        has             O\n",
       "12       made             O\n",
       "13        and             O\n",
       "14     Google  ORGANIZATION\n",
       "15      stock             O\n",
       "16       jump             O\n",
       "17         by             O\n",
       "18          5             O\n",
       "19          %             O\n",
       "20        Dow             O\n",
       "21      Jones             O\n",
       "22      Index             O\n",
       "23        the             O\n",
       "24     United      LOCATION\n",
       "25     States      LOCATION\n",
       "26         of      LOCATION\n",
       "27    America      LOCATION"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = nltk.word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "classified_text_df = pd.DataFrame(classified_text)\n",
    "\n",
    "classified_text_df.drop_duplicates(keep='first', inplace=True)\n",
    "classified_text_df.reset_index(drop=True, inplace=True)\n",
    "classified_text_df.columns = [\"Entities\", \"Labels\"]\n",
    "classified_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Entities        Labels\n",
       "0                     Apple  ORGANIZATION\n",
       "1                     China      LOCATION\n",
       "2  United States of America      LOCATION\n",
       "3                    Google  ORGANIZATION"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = nltk.word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "netagged_words = classified_text\n",
    "\n",
    "entities = []\n",
    "labels = []\n",
    "\n",
    "from itertools import groupby\n",
    "for tag, chunk in groupby(classified_text, lambda x:x[1]):\n",
    "    if tag != \"O\":\n",
    "        entities.append(' '.join(w for w, t in chunk))\n",
    "        labels.append(tag)\n",
    "        \n",
    "        \n",
    "entities_all = list(zip(entities, labels))\n",
    "entities_unique = list(set(zip(entities, labels))) #unique entities   \n",
    "entities_df = pd.DataFrame(entities_unique)\n",
    "entities_df.columns = [\"Entities\", \"Labels\"]\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://spacy.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "from spacy import displacy\n",
    "#SpaCy 2.x brough significant speed and accuracy improvements\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download spacy models\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp = spacy.load(\"en_core_web_md\")\n",
    "#nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Position_Start</th>\n",
       "      <th>Position_End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Apple)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Zoom)</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(China)</td>\n",
       "      <td>GPE</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Wednesday, 6th)</td>\n",
       "      <td>DATE</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Apple)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Google)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(5, %)</td>\n",
       "      <td>PERCENT</td>\n",
       "      <td>105</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Dow, Jones)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>111</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(the, United, States, of, America)</td>\n",
       "      <td>GPE</td>\n",
       "      <td>130</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Entities   Labels  Position_Start  Position_End\n",
       "0                             (Apple)      ORG               0             5\n",
       "1                              (Zoom)   PERSON              15            19\n",
       "2                             (China)      GPE              23            28\n",
       "3                    (Wednesday, 6th)     DATE              32            45\n",
       "4                             (Apple)      ORG              74            79\n",
       "5                            (Google)      ORG              84            90\n",
       "6                              (5, %)  PERCENT             105           107\n",
       "7                        (Dow, Jones)      ORG             111           120\n",
       "8  (the, United, States, of, America)      GPE             130           158"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "entities = []\n",
    "labels = []\n",
    "position_start = []\n",
    "position_end = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    entities.append(ent)\n",
    "    labels.append(ent.label_)\n",
    "    position_start.append(ent.start_char)\n",
    "    position_end.append(ent.end_char)\n",
    "    \n",
    "df = pd.DataFrame({'Entities':entities,'Labels':labels,'Position_Start':position_start, 'Position_End':position_end})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spacy works the best**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What you can build with this?**\n",
    "\n",
    "- A bot that can analyze financial news and extract information about entities that are mentioned in a <br>\n",
    "given article along with location, dates and numeric information. This information can be further utilized<br> in building algorithmic trading bots<br>\n",
    "<br>\n",
    "- Analyze research papers produced everyday on COVID19 and find out any significant developments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
